---
layout: default
title: Ongoing Research
permalink: /research/
---

<script>
document.body.classList.add('research-page');
</script>

# LLM-Mediated Data Sensemaking: Exploring Teachers' Reflective Practice in AI-Supported Science Learning

![Research Framework]({{ "/images/LLMDataSensemaking1.png" | relative_url }})
{: style="width: 120%; max-width: 120%; margin-left: -10%; margin-right: -10%; margin-top: 2em; margin-bottom: 2em;"}

## Introduction

As large language models (LLMs) enter classrooms, teachers are increasingly challenged to integrate these tools to support students' data sensemaking in science learning. Data has become central to science education, yet making sense of it requires both technical and conceptual skills. Teachers must therefore navigate complex pedagogical decisions about how to employ LLMs that can generate, interpret, and visualize data while being aware of their limitations, such as bias, incompleteness, or hallucinations. This research investigates how teachers, through reflective practices, effectively facilitate students' sensemaking of data using LLMs. Grounded in human-centered AI and learning sciences, the study focuses on teachers, as both learners and facilitators, developing pedagogical, technological, and content knowledge for LLM-mediated data sensemaking.

## Research Design and Methodology

This study employs a qualitative comparative case study with three in-service high school science teachers, exploring their experiences through three stages: **Teachers-as-Learners**, **Teachers-as-Designers**, and **Teachers-as-Implementers**. In each stage, teachers interact with an LLM-mediated data analysis pipeline (Figure 1) that scaffolds the data sensemaking process, from data collection to visualization, through iterative prompting and decision-making. Teachers collaborate with the LLM to analyze datasets of their choice, applying techniques such as zero-shot, few-shot, and chain-of-thought prompting. At each stage, teachers develop and apply evaluation and decision criteria to determine whether to accept, reject, or revise the model's outputs. Data sources include semi-structured interviews, surveys, reflection journals, AI chat logs, and co-design artifacts. This study design foregrounds reflective practice—reflection-for-action, in-action, and on-action—as teachers use their emerging knowledge of working with LLM for data sensemaking to inform their pedagogical practice and support for their students.

## Analysis and Expected Outcomes

This study combines thematic analysis of teacher reflections and interviews with LLM output evaluation using a human-in-the-loop approach, integrating both LLM-as-a-Judge and teacher judgment to assess data analysis quality and interpretability. Cross-case analysis will highlight how teachers' understanding of AI evolves as they learn, design, and implement AI-supported instruction. Anticipated outcomes will include a framework for LLM-mediated data sensemaking that captures how teachers' reflective cycles shape their pedagogical reasoning, evaluation criteria, and instructional design. This framework will inform teacher professional development, providing insights into how educators can critically and productively integrate LLMs into data-intensive science learning. More broadly, this study contributes to LLM evaluation research by positioning teachers as both evaluators and co-designers in a human-centered AI learning ecosystem.

---

[← Back to Home]({{ "/" | relative_url }})
